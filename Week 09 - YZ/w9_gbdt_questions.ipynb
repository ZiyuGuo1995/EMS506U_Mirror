{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09bad5da",
   "metadata": {},
   "source": [
    "## Classical ML regression\n",
    "\n",
    "All of this exercise is important for the course work!\n",
    "\n",
    "We will use a gradient boosted regressor to fit the same dataset as win week 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab90f91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347a1f9f",
   "metadata": {},
   "source": [
    "## Load up the data\n",
    "\n",
    "We use pandas to read in the data. In this case the first 6 columns (0-5) are the features and the final column (6) are the labels. The code to do this is:\n",
    "```\n",
    "df_train = pd.read_pickle('../Week 11/week2-regression-train.pickle')\n",
    "x = df_train.values[:, :6]\n",
    "y = df_train.values[:, 6]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049968d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc5af3d1",
   "metadata": {},
   "source": [
    "## Standardise the data\n",
    "\n",
    "We then standardise the data using the `StandardScaler`. **Note** if the data has only one feature, like the label data y, we need to use a reshape when standardising. The code to do this is:\n",
    "```\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_x = StandardScaler()\n",
    "x = scaler_x.fit_transform(x)\n",
    "scaler_y = StandardScaler()\n",
    "y = scaler_y.fit_transform(y.reshape(-1, 1))\n",
    "```\n",
    "\n",
    "We then use the `train_test_split` function to make separate training and test sets; use 80% to train and 20% to test. You should be able to do this without a code hint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78543510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28908c81",
   "metadata": {},
   "source": [
    "## Split into train and test sets\n",
    "```\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0,\n",
    "                                  train_size=0.8)\n",
    "                                  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c302b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "241db35a",
   "metadata": {},
   "source": [
    "## Train a model\n",
    "\n",
    "We will train a gradient boosted regressor, using the default hyperparameters. The code to do this is:\n",
    "```\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "regr = GradientBoostingRegressor()\n",
    "regr.fit(x_train, y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a3741c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fa707c0",
   "metadata": {},
   "source": [
    "## Visually inspect the performance of the model\n",
    "\n",
    "Get the predictions of the model on the test set. Use `predictions = regr.predict(x_test)` to make predictions.\n",
    "\n",
    "Use a scatter plot from matplotlib to plot `predictions` versus `y_test`. Don't forget to label your axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873f4436",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d55b3412",
   "metadata": {},
   "source": [
    "## Calculate the metrics for the model performace\n",
    "\n",
    "Use the same kind of performace metrics that you used in the exercise for linear regression to compare the `predictions` to `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6a6f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f41435b7",
   "metadata": {},
   "source": [
    "## Perform hyper-parameter tuning\n",
    "\n",
    "Watch part 3 of the practical video to see how to do this specifically.\n",
    "\n",
    "Here we will use `GridSearchCV` from `sklearn.model_selection` to search for the best combination of hyperparameters.\n",
    "Specifically we will tune the number of estimators, maximum depth, minimum samples required for a split and the learning rate.\n",
    "\n",
    "To get the names of the hyperparameters use `regr.get_params().keys()`\n",
    "\n",
    "Set up the distributions to optmise over (for example):\n",
    "```\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200, 500, 1000],\n",
    "    \"learning_rate\": [0.098, 0.099, 0.1 , 0.101, 0.102]\n",
    "}\n",
    "```\n",
    "Set up the cross-validation based search:\n",
    "```\n",
    "search_cv = GridSearchCV(\n",
    "    regr, param_grid=param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\",  n_jobs=2, cv=10\n",
    ")\n",
    "```\n",
    "Perform the search\n",
    "```\n",
    "search_cv.fit(x_train, y_train.ravel())\n",
    "```\n",
    "This will take a few minutes to complete\n",
    "\n",
    "Get the best parameters with\n",
    "```\n",
    "print(search_cv.best_params_)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc299b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a17026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01671cc5",
   "metadata": {},
   "source": [
    "## Check to see what the optimal set of parameters are\n",
    "\n",
    "You can get this by printing `search_cv.best_params_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3e229a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cdf3a9f",
   "metadata": {},
   "source": [
    "## Look at the performace of the best model\n",
    "\n",
    "You can select the best model using:\n",
    "```\n",
    "best_regr = search_cv.best_estimator_\n",
    "```\n",
    "Now use this `best_regr` similar to how you used `regr` above to visually look at the results and to visually inspect the performace and calculate metrics.\n",
    "\n",
    "How does the tuned model compare to the default model?\n",
    "\n",
    "How do these models compare to the linear regression from last week?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a8eb1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fb5158",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
