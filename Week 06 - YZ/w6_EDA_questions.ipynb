{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a10182da",
   "metadata": {},
   "source": [
    "## Week 6 exercise\n",
    "\n",
    "All of the functions and code that you need for this exercise will be covered in the notebook from Week 9 called *lecture-1-exploratory-data-analysis.ipynb*\n",
    "\n",
    "Parts 1, 4 and 5 of this notebook will be important for your coursework.\n",
    "\n",
    "You are given a dataset of materials. This data contains both inter-metallic materials and ionic materials. The data also has a series of features that describe each material. Your task this week is to explore the relationships between the descriptors. Look for any suspicious data. Decide if any descriptors are very highly correlated. Reduce the dimensionality and look at some initial clustering of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a07e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb4ce17",
   "metadata": {},
   "source": [
    "## 1 Load and look at the data\n",
    "\n",
    "* Use pandas to read `training-data-week-1.pickle`.\n",
    "```\n",
    "df = pd.read_pickle('training-data-week-1.pickle')\n",
    "```\n",
    "* Take a look at the top few entries of this data frame. See part 2 of *lecture-1-exploratory-data-analysis.ipynb*.\n",
    "```\n",
    "df.head()\n",
    "```\n",
    "* Explore some non-graphical summary statistics of the different columns using pandas. See part 2 of *lecture-1-exploratory-data-analysis.ipynb*.\n",
    "```\n",
    "df.describe()\n",
    "```\n",
    "* Get information about the types of data in each column using pandas. See part 2 of *lecture-1-exploratory-data-analysis.ipynb*.\n",
    "```\n",
    "df.info()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40fa5e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efee9bea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908a482a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11aa221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ff9f1d3",
   "metadata": {},
   "source": [
    "## 2 Graphical examination\n",
    "\n",
    "Use seaborn to plot scatters of the different variables against each other.\n",
    "\n",
    "```\n",
    "import seaborn as sns\n",
    "sns.pairplot(df)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7170929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcc7386e",
   "metadata": {},
   "source": [
    "## 3 Inspect the individual distributions\n",
    "\n",
    "For each column calculate the skew and the kurtosis for each of the columns. Which data has the highest skew and the highest kurtosis?\n",
    "You can get a list of columns using:\n",
    "\n",
    "```\n",
    "column_names = list(df.columns)\n",
    "print(column_names)\n",
    "```\n",
    "\n",
    "\n",
    "Use the code for `skew` and `kurt` from lecture 1 [in the ebook](https://keeeto.github.io/ebook-data-analysis/lecture-1-exploratory-data-analysis.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69673972",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e5266e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f5d4af3",
   "metadata": {},
   "source": [
    "## 4 Using boxplots \n",
    "\n",
    "Inspect each column and look for outliers \n",
    "* Make box plots for each of the columns\n",
    "    * If you find a very serious outlier (say more than 1000 away from the mean value) drop it from the data - you will see the box plot disappear\n",
    "    * If you find a bad outlier - remove that data\n",
    "* Save the new clean dataframe to `week1-cleaned-data.pickle`\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d54194",
   "metadata": {},
   "source": [
    "### Plot the box plots\n",
    "\n",
    "Get the number of features : `print(len(list(df.columns)))`\n",
    "\n",
    "In this case we have 9 features - so we can do a 3x3 plot. Use this code:\n",
    "```\n",
    "column_names = list(df.columns)\n",
    "fig, ax = plt.subplots(3, 3, figsize=(10, 10))\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        data = df[df.columns[3*i + j]].values\n",
    "        ax[i, j].boxplot(data)\n",
    "        ax[i, j].set_title(df.columns[3*i + j])\n",
    "plt.tight_layout()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb13f119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca2b4ef0",
   "metadata": {},
   "source": [
    "### Identify outliers\n",
    "\n",
    "Are there any box plots where there are points more than 1000 aaway from the mean?\n",
    "If there are any - drop these rows from the data.\n",
    "\n",
    "To drop the data, you can locate it using something like\n",
    "```\n",
    "df.drop(df[df['column name'] >= 1000].index, inplace = True)\n",
    "```\n",
    "\n",
    "When you have dropped the outliers, save the dataset:\n",
    "```\n",
    "df.to_pickle('week1-cleaned-data.pickle')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e312419f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c31a2f9a",
   "metadata": {},
   "source": [
    "Do the 3x3 boxplots again and make sure outliers are gone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab6182a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a2d7eac",
   "metadata": {},
   "source": [
    "## 5 Correlations\n",
    "\n",
    "Obtain the pearson correlations between the different columns and inspect them.\n",
    "Which columns seems to be most closely related - are there any possibly redundant columns that you might remove?\n",
    "\n",
    "The code for plotting Pearson correlations in a heatmap is in lecture 1 [in the ebook](https://keeeto.github.io/ebook-data-analysis/lecture-1-exploratory-data-analysis.html).\n",
    ". It is in the section *Explore correlations in the data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5a02e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0095d2e0",
   "metadata": {},
   "source": [
    " Drop correlated data. \n",
    "```\n",
    "df.drop([<list of columns to drop>], inplace=True, axis=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46519bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d08efa8",
   "metadata": {},
   "source": [
    "Plot the heatmap again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5c6e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29c56174",
   "metadata": {},
   "source": [
    "## 6 Look at data reduction and clustering (not needed for the course work, but useful)\n",
    "\n",
    "We will see if we can cluser the data to separate those oxides with bandgaps and intermetallics with no band gaps.\n",
    "First try it on the raw data, we will look for exmaple at the columns `Eneg avg_dev` and `Radius avg_dev`, colouring the points by the true labels and we will see how this shows up.\n",
    "\n",
    "**Hint** The code you need for this can be found in the notebook from Week 9 *lecture-2-pca.ipynb* and lecture 2  [in the ebook](https://keeeto.github.io/ebook-data-analysis/lecture-2-clustering-kmeans-GMM.html).\n",
    "\n",
    "* Plot `Eneg avg_dev` and `Radius avg_dev`, colour the points by the true labels (called 'labels' in this data). Use the following syntax:\n",
    "```\n",
    "plt.scatter(df['<variable 1>'].values, df['<variable 2>'].values, c=df['<variable for colour>'].values)\n",
    "```\n",
    "* Do a PCA with the same number of principal components as columns\n",
    "* Use this to work out how many componants can accoun for about 99% of the variance\n",
    "* Do a scatter plot in 2d of the first two compononents - colour the plot by the band_gap values - do you see a trend?\n",
    "* Try to cluster this data using k-means\n",
    "    * Use the code from *lecture-2-clustering-kmeans-GMM.ipynb*\n",
    "        * Section - `Clustering using k-means`\n",
    "\n",
    "\n",
    "# NB\n",
    "\n",
    "Before doing the PCA etc convert the dataframe to an array and make sure you drop the label column. Use the code below:\n",
    "\n",
    "    X = df.values\n",
    "    labels = X[:, 9]\n",
    "    X = X[:, :9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d430ea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the two columns mentioned above\n",
    "# Note that c means colour and we will colour by the bandgap, column 8\n",
    "plt.scatter(df['Eneg avg_dev'].values, df['Radius avg_dev'].values, c=df['labels'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eb7aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.values\n",
    "labels = X[:, 7]\n",
    "X = X[:, :7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1737a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=6).fit(X)\n",
    "plt.plot(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee1e954",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_out = PCA(n_components=2).fit_transform(X)\n",
    "labels[labels > 0] = 1\n",
    "plt.scatter(pca_out[:, 0], pca_out[:, 1], c=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abad42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(X)\n",
    "y_kmeans = kmeans.predict(X)\n",
    "plt.scatter(pca_out[:, 0], pca_out[:, 1], c=y_kmeans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
